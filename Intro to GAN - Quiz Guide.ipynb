{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DC GAN QUIZ GUIDE",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zeXJKLNesg8",
        "colab_type": "text"
      },
      "source": [
        "## Generative Adverserial Network Quiz\n",
        "\n",
        "This notebook is contains guide and questions in order to complete the quiz. Plase mind that this quiz is semi-progressive, means that in order to answer future questions you might have to complete the previous one. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLjrWfpark81",
        "colab_type": "text"
      },
      "source": [
        "#  <font color=\"red\">**QUESTION 1**</font> \n",
        "GAN is a generative model. Please select all box that represents a generative models :\n",
        "- [ ] Naive Bayes\n",
        "- [ ] Logistic Regression\n",
        "- [ ] Support Vector Machine\n",
        "- [ ] K-Nearest Neighbor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh0fCiKMrqbD",
        "colab_type": "text"
      },
      "source": [
        "#  <font color=\"red\">**QUESTION 2**</font> \n",
        "What does adversarial refers to in GAN ? \n",
        "- [ ] Loss function\n",
        "- [ ] Optimizer\n",
        "- [ ] Input\n",
        "- [ ] Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-7d7pcssDm6",
        "colab_type": "text"
      },
      "source": [
        "#  <font color=\"red\">**QUESTION 3**</font> \n",
        "Select all correct boxes  \n",
        "- [ ] Generator takes input from Discriminator\n",
        "- [ ] Discriminator tries to maximize the loss function\n",
        "- [ ] Discriminator tries to generate a random noise \n",
        "- [ ] GAN input is random vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdJ6GF5EuR5w",
        "colab_type": "text"
      },
      "source": [
        "Now, let's your comprehension in implementing GAN (DC GAN). These codes contains blank (\"?\" marks) that you should fill to complete and andswer the questions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxRvtgPeesg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.layers import Reshape, UpSampling2D, MaxPooling2D, Activation\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh_ZsU26gPiF",
        "colab_type": "text"
      },
      "source": [
        "### Load MNIST Dataset\n",
        "In this quiz, we will use MNIST Fashion dataset. Please write your code on the \"??\" mark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obPzmoTKcdbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load mnist fashion data\n",
        "(X_train, y_train), (X_test, y_test) = ?? \n",
        "\n",
        "# Do a basic normalization as shown in class\n",
        "X_train = ??\n",
        "\n",
        "X_train = X_train[:, :, :, None]\n",
        "X_test = X_test[:, :, :, None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ppsDDPqlDGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (X_train.shape, X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE30rWZ5mKBV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#  <font color=\"red\">**QUESTION 4**</font> \n",
        "To ensure you have correctly load the data, what is the shape of X_train and X_test respectively?\n",
        "- [ ] (60000, 28, 28, 1) and (10000, 28, 28, 1)\n",
        "- [ ] (50000, 28, 28, 1) and (5000, 28, 28, 1)\n",
        "- [ ] (60000, 32, 32, 1) and (10000, 32, 32, 1)\n",
        "- [ ] (50000, 32, 32, 1) and (5000, 32, 32, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvrcHmZd0j9s",
        "colab_type": "text"
      },
      "source": [
        "#  <font color=\"red\">**QUESTION 5**</font> \n",
        "While loading the Mnist dataset, in line 4, what does `X_train = (X_train.astype(np.float32) - 127.5)/127.5 ` means ?\n",
        "\n",
        "- [ ] Rescale the data into within the interval of -1 to 1\n",
        "- [ ] Rescale the data into within the interval of 0 to 1\n",
        "- [ ] Denormalize data\n",
        "- [ ] Reshape data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD88W-oreshI",
        "colab_type": "text"
      },
      "source": [
        "### Generator Model\n",
        "Create a generator for your GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz4mo0KeeshJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_model():\n",
        "    model = Sequential([\n",
        "        Dense(1024, input_dim=100, activation='tanh'),\n",
        "        Dense(128*7*7),\n",
        "        BatchNormalization(),\n",
        "        Activation('tanh'),\n",
        "\n",
        "        # Do a reshape to make data shape into (7, 7, 128). Hint: Use Reshape()\n",
        "        ??\n",
        "\n",
        "        UpSampling2D(size=(2, 2)),\n",
        "        Conv2D(64, (5, 5), padding='same', activation='tanh'),\n",
        "\n",
        "        # Do upsampling with size (2,2). Hint: use UpSampling2D()\n",
        "        ??\n",
        "\n",
        "        # Complete the conv2D with total number of filter=1 and filter size=5x5 \n",
        "        Conv2D(?, (?, ?), padding='same', activation='tanh')\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgasIek7rOeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_model().summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3kkY9Q5wPDt",
        "colab_type": "text"
      },
      "source": [
        "#  <font color=\"red\">**QUESTION 6**</font> \n",
        "How many params does the generator_model has ? \n",
        "- [ ] 6,765,313\n",
        "- [ ] 6,763,777\n",
        "- [ ] 6,751,233\n",
        "- [ ] 12,544"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_PpwJS7wvh4",
        "colab_type": "text"
      },
      "source": [
        "#  <font color=\"red\">**QUESTION 7**</font> \n",
        "If you change the last convolution layer's filter shape into 7x7, what will be the final total parameters ?\n",
        "- [ ] 6,765,313\n",
        "- [ ] 6,763,777\n",
        "- [ ] 6,741,233\n",
        "- [ ] 12,700"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOdQvTIheshO",
        "colab_type": "text"
      },
      "source": [
        "### Discriminator Model\n",
        "Create a discriminator for your GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ04Wj52eshQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (5, 5), input_shape=(28, 28, 1), padding='same', activation='tanh'),\n",
        "        \n",
        "        # add max pooling with pool size 2x3\n",
        "        ?? \n",
        "        Conv2D(128, (5, 5),activation='tanh'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "\n",
        "        # Add Dense containing 1024 neurons with activation function ='tanh' \n",
        "        ?\n",
        "\n",
        "        # Add single neuron (dense) with actiation='sigmoid'\n",
        "        ?\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhKxXNQHxyCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_model().summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ8z_Zjey9Ta",
        "colab_type": "text"
      },
      "source": [
        "#  <font color=\"red\">**QUESTION 8**</font> \n",
        "What does Flatten() layer means in the Discriminator?\n",
        "- [ ] To make the data standardized \n",
        "- [ ] To make the data mean = 0\n",
        "- [ ] To reshape the data into one dimensional vector\n",
        "- [ ] To compile the previous layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go4bbqd9eshZ",
        "colab_type": "text"
      },
      "source": [
        "### GAN = Generator + Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lakdtO03esha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_model(g, d):\n",
        "    model = Sequential()\n",
        "    model.add(g)\n",
        "    model.add(d)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaa7lbqgeshe",
        "colab_type": "text"
      },
      "source": [
        "## Training Functions\n",
        "untuk melakukan training diperlukan BATCH_SIZE yang merupakan banyaknya gambar yang di train tiap epochs nya. Tiap piksel gambar akan dikonversikan menjadi nilai antara [-1,1). Hasil training akan disimpan pada file discriminator dan generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42dCuaj3n9lk",
        "colab_type": "text"
      },
      "source": [
        "### Combine Generated Image\n",
        "\n",
        "Combine Image adalah fungsi untuk menggabungkan gambar kedalam satu frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB_HZV1Peshh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_images(generated_images):\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(np.sqrt(num))\n",
        "    height = int(np.ceil(float(num)/width))\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, 0]\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ6y9x9xn_3b",
        "colab_type": "text"
      },
      "source": [
        "### Training Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctJzIyAJeshl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_gan(X_train, Y_train, batch_size, epochs, g, d, save_every=500, print_every=100):\n",
        "    \n",
        "    # ukuran vektor z\n",
        "    z_size = g.layers[0].input_shape[1]\n",
        "    \n",
        "    # gabungkan Discriminator dan Generator\n",
        "    d.trainable = False # set Discriminator tidak bisa dilatih sebelum digabung\n",
        "    d_on_g = combine_model(g, d)    \n",
        "    dg_optim = RMSprop (lr=0.0005)\n",
        "    g_optim = RMSprop (lr=0.0005)\n",
        "    d_on_g.compile(loss='binary_crossentropy', optimizer=dg_optim)\n",
        "    \n",
        "    g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
        "    \n",
        "    # set Discriminator agar bisa dilatih kembali\n",
        "    d.trainable = True\n",
        "    d_optim = RMSprop (lr=0.0005)\n",
        "    d.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
        "    \n",
        "    print(\"Number of batches\", int(X_train.shape[0]/batch_size))\n",
        "    \n",
        "    # mulai pelatihan\n",
        "    for epoch in range(epochs):\n",
        "        print(\"\\n-------------------------------\\nEpoch :\", epoch)        \n",
        "        \n",
        "        for index in range(int(X_train.shape[0]/batch_size)):\n",
        "            \n",
        "            # bangkitkan matrix z secara acak\n",
        "            noise = np.random.uniform(-1, 1, size=(batch_size, z_size))\n",
        "            \n",
        "            # bangkitkan data gambar palsu dari matrix z\n",
        "            generated_images = g.predict(noise, verbose=0)\n",
        "            \n",
        "            # ambil data gambar asli\n",
        "            image_batch = X_train[index*batch_size:(index+1)*batch_size]\n",
        "            \n",
        "            if index % save_every == 0:\n",
        "                image = combine_images(generated_images)\n",
        "                image = image*127.5+127.5\n",
        "                # Image.fromarray(image.astype(np.uint8)).save(\"train_ep\"+\n",
        "                #     str(epoch)+\"_\"+str(index)+\".png\")\n",
        "                \n",
        "                plt.imshow(image, cmap=plt.get_cmap('gray'))\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "                \n",
        "            # gabungkan data untuk pelatihan Discriminator\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            y = [1] * batch_size + [0] * batch_size\n",
        "            \n",
        "            # latih Discriminator\n",
        "            d_loss = d.train_on_batch(X, y)           \n",
        "            \n",
        "            # bangkitkan matrix z secara acak untuk pelatihan Generator\n",
        "            noise = np.random.uniform(-1, 1, (batch_size, z_size))\n",
        "            \n",
        "            # set Discriminator tidak bisa dilatih sebelum digabung\n",
        "            d.trainable = False            \n",
        "            \n",
        "            # latih Generator\n",
        "            g_loss = d_on_g.train_on_batch(noise, [1] * batch_size)\n",
        "            \n",
        "            # print loss\n",
        "            if index % print_every == 0: \n",
        "                print(\"batch %d, g_loss : %f, d_loss : %f\" % (index, g_loss, d_loss))\n",
        "            \n",
        "            # set Discriminator agar bisa dilatih kembali\n",
        "            d.trainable = True       \n",
        "            \n",
        "        \n",
        "    return g, d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkFnvwjQoCOp",
        "colab_type": "text"
      },
      "source": [
        "## Training Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEsyFQUPnJFp",
        "colab_type": "text"
      },
      "source": [
        "### Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zb1d61beshU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_size = 100\n",
        "g_model = generator_model()\n",
        "d_model = discriminator_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "564IaJunwsEZ",
        "colab_type": "text"
      },
      "source": [
        "### Train GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "a_zwpKTyesht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 225\n",
        "epochs = 20\n",
        "g_model, d_model = train_gan(X_train,y_train, batch, epochs, g_model, d_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKsn2emweshy",
        "colab_type": "text"
      },
      "source": [
        "## Generate image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsBrii5KesiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = np.random.uniform(-1, 1, (4, 100))\n",
        "images = g_model.predict(seed)\n",
        "\n",
        "for i in range(4):\n",
        "    plt.subplot(2,2,1+i)\n",
        "    plt.imshow(np.reshape(images[i], (28,28,)),cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyagPNWysqHa",
        "colab_type": "text"
      },
      "source": [
        "### Generate image from generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izeeWEhIeshy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_images(g, batch_size):\n",
        "    z_size = g.layers[0].input_shape[1]\n",
        "    noise = np.random.uniform(-1, 1, (batch_size, z_size))\n",
        "    generated_images = g.predict(noise, verbose=1)\n",
        "    image = combine_images(generated_images)\n",
        "    filename = \"generated_image.png\"\n",
        "    image = image*127.5+127.5\n",
        "    Image.fromarray(image.astype(np.uint8)).save(filename)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20IGMkKGesh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = generate_images(g_model, 100)\n",
        "plt.imshow(images, cmap=plt.get_cmap('gray'))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCcO6WjRsV5p",
        "colab_type": "text"
      },
      "source": [
        "### Generate image with the check of discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCdIPuwhesh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_best_images(g, d, batch_size):\n",
        "    z_size = g.layers[0].input_shape[1]\n",
        "    noise = np.random.uniform(-1, 1, (batch_size*20, z_size))\n",
        "\n",
        "    generated_images = g.predict(noise, verbose=1)\n",
        "    d_pret = d.predict(generated_images, verbose=1)\n",
        "\n",
        "    index = np.arange(0, batch_size*20)\n",
        "    index.resize((batch_size*20, 1))\n",
        "\n",
        "    pre_with_index = list(np.append(d_pret, index, axis=1))\n",
        "    pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    nice_images = np.zeros((batch_size,) + generated_images.shape[1:3], dtype=np.float32)\n",
        "    nice_images = nice_images[:, :, :, None]\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        idx = int(pre_with_index[i][1])\n",
        "        nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
        "\n",
        "    image = combine_images(nice_images)\n",
        "    filename = \"generated_image_best.png\"\n",
        "    image = image*127.5+127.5\n",
        "    Image.fromarray(image.astype(np.uint8)).save(filename)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_tIkXNzesh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = generate_best_images(g_model, d_model, 100)\n",
        "plt.imshow(images, cmap=plt.get_cmap('gray'))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcC3jn6u2UaU",
        "colab_type": "text"
      },
      "source": [
        "#  <font color=\"red\">**QUESTION 9**</font> \n",
        "what is the differences between images that are not checked by discriminator (directly generated from generator), and images that previously checked by discriminator?\n",
        "- [ ] The unchecked images are smaller in size\n",
        "- [ ] The checked images are usually better \n",
        "- [ ] The unchecked images are usually better\n",
        "- [ ] The checked images are smaller in size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpKFjlGM3mjQ",
        "colab_type": "text"
      },
      "source": [
        "#  <font color=\"red\">**QUESTION 10**</font> \n",
        "What do you think about losses over time while training ? \n",
        "- [ ] It will be minimized overtime\n",
        "- [ ] It will be maximized overtime\n",
        "- [ ] It will just fluctuate randomly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjjRNUnV5MN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}