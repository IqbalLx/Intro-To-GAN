<!DOCTYPE html><html><head>
      <title>Blogpost</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\dzul\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.5.0\node_modules\@shd101wyy\mume\dependencies\katex\katex.min.css">
      
      

      
      
      
      
      
      
      

      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <h1 class="mume-header" id="an-introduction-to-generative-adversarial-network-gan">An Introduction to Generative Adversarial Network (GAN)</h1>

<p>Prerequisites:</p>
<ul>
<li>CNN</li>
<li>Keras</li>
</ul>
<h1 class="mume-header" id="intro">Intro</h1>

<p><img src="res\edmond-de-belamy-framed-cropped.jpg" alt></p>
<blockquote>
<p>Is artificial intelligence set to become art&#x2019;s next medium? - Chritie&apos;s</p>
</blockquote>
<p>In 2018 a  paint of Edmond de Belamy made by machine learning (GAN) was sold for $432,500 in online auction, Christie&apos;s. This made Chritie&apos;s the first auction house that sell works created by machine learning. On an unbelievable price. What do you think about this ? Will machine learning help us create arts, or will it kill our creativity?</p>
<p>As discovered by Ian Goodfellow<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup> , GAN is consisted of <strong>two</strong> neural networks named Generator and Discriminator. The Generator was built to create fake images, while the discriminator was built to identify those fake images as fake. Essentially, it&apos;s not always have to be fake image. The GAN architecture can build any other type of data like sounds or videos.</p>
<h2 class="mume-header" id="course-objective">Course Objective :</h2>

<ul>
<li>Implement (not optimize) DC-GAN</li>
<li>Operate Latent Vector</li>
</ul>
<h2 class="mume-header" id="motivational-examples">Motivational Examples</h2>

<p>Before we go into implementation of GAN, let&apos;s see how GAN(s) changes overtime.</p>
<p><img src="res\gan-tweet.PNG" alt></p>
<p>Since it&apos;s first appearance in 2014, and with the rising of Computer Vision - CNN, GAN grew rapidly. It&apos;s now able to generate a stunning images, that even our eyes cannot distinguish whether it&apos;s real or fake! Current most state-of-the-art GAN are StyleGAN, and you can check it&apos;s result in <a href="thispersondoesntexist.com">thispersondoesntexist.com</a>. Let&apos;s see several types of GANs</p>
<h3 class="mume-header" id="cgan-conditional-gan-2014">CGAN (Conditional GAN, 2014)</h3>

<hr>
<p><img src="res\cgan.PNG" alt></p>
<hr>
<p>GAN was originally created to be trainable with only <strong>ONE</strong> class. If you train your GAN with dog images, it can generate dog images. If you train your GAN with cat images, it can generate cat images. But, what if your GAN was trained into both cat and dog images ? It will generate a blurry animal. To overcome this, Mirza<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup> created CGAN that can diffrentiate multiple output.</p>
<p>This work also make it possible to guide an image into something else like example below</p>
<hr>
<p><img src="res\pose-guide.png" alt><br>
<sub><em>source: <a href="https://papers.nips.cc/paper/6644-pose-guided-person-image-generation.pdf">https://papers.nips.cc/paper/6644-pose-guided-person-image-generation.pdf</a></em></sub></p>
<hr>
<h3 class="mume-header" id="cyclegan-2018">CycleGAN, 2018</h3>

<p>In 2018, Zu<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> create a CycleGAN, A GAN that <strong>Doesn&apos;t Generate Fake Images</strong>. Instead, it transfer styles between images.</p>
<p>Have you ever imagin a horse with zebra lines ?<br>
<img src="res\zebra-horse.gif" alt></p>
<p>Or, playing Fortnite with PUBG style?<br>
<img src="res\fortnite-pubg.gif" alt></p>
<p>Unlike <a href="https://towardsdatascience.com/style-transfer-styling-images-with-convolutional-neural-networks-7d215b58f461">Style Transfer</a>, cycle gan is not limited by domain, wich means, you can do text-to-image style transfer!<br>
<img src="res\text-image.png" alt></p>
<p><sub>Sources: <a href="https://junyanz.github.io/CycleGAN/">Zebra-Horse</a>,<a href="https://towardsdatascience.com/turning-fortnite-into-pubg-with-deep-learning-cyclegan-2f9d339dcdb0">Fortnite-PUBG</a>, <a href="https://arxiv.org/pdf/1808.04538.pdf">text-image</a><br>
</sub></p>
<h3 class="mume-header" id="sagan-self-attention-gan-2018">SAGAN (Self Attention GAN, 2018)</h3>

<p>After Computer Vision takes over ML&apos;s attentions for years, eventually it face a saturation phase, where it&apos;s considered as State-of-the-art model for Image Classifiation, Detection, Segmentations, etc. There&apos;s nothing such a new architecture, everything is CNN. That&apos;s when NLP kicks in. Thanks for <a href="https://blog.scaleway.com/2019/building-a-machine-reading-comprehension-system-using-the-latest-advances-in-deep-learning-for-nlp/">Transformers</a>, NLP started to find a new hope, and generated a model called <a href="https://medium.com/@joealato/attention-in-nlp-734c6fa9d983">Attention</a>. This idea then inspired Zhang<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup> to create a Self Attention GAN that can help them focus on the context of the images. His model then considered as the state-of-the art GAN. But not for a long time.<br>
<img src="res\sagan.png" alt></p>
<h3 class="mume-header" id="progan-2018">ProGAN (2018)</h3>

<p>Training GAN is hard. Knowing that the Generator and Discriminator fighting each other, GAN losses somethimes become unstable and can jumped just after the model started to look converge.</p>
<p><img src="res\progan.gif" alt><br>
<sub>Source: <a href="https://cdn-images-1.medium.com/max/1600/1*tUhgr3m54Qc80GU2BkaOiQ.gif">Medium</a><br>
</sub></p>
<p>In order to face that, Karras<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup> and his mates from NVIDIA started to build a GAN that gradually increasing it&apos;s size in order to maintain training stability. This method get a lot of compliment as it nominated as state-of-the-art.</p>
<h3 class="mume-header" id="biggan-2019">BigGAN (2019)</h3>

<p>In 2019, Brock<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup> and his teammates from Google Deepmind attempted to create a GAN that run on a large scale of TPU cluster. Hence the name, BigGAN. No one have ever tried to train GAN on such a large cluster of machine. Now you know the power of Google.</p>
<p><img src="res\big-gan.png" alt><br>
<sub>Source: Brock&apos;s Paper<br>
</sub></p>
<p>Despite it&apos;s kind of meaningless name, this model really, really, made an improvement of GAN. It can generate very realistic images in large dimension (512x512). It&apos;s inception score also killed the previous state-of-the art models from 52.52 into 166.5.</p>
<h3 class="mume-header" id="stylegan">StyleGAN</h3>

<p>GANs already reach its point wich it can generate a hyper-realistic images. But GAN it&apos;s such a meaningless if we can&apos;t generate another object from it.<br>
Still from NVIDIA instead of continue creating more realistic images, Karras<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup> focused on making GAN that can be controlled over a style, hence the name StyleGAN. This mean you have big control of what image will you generate. Or more likely, How do you want the image to be.</p>
<p><img src="res\stylegan2.png" alt><br>
<sub>Source: Karras&apos;s Paper<br>
</sub></p>
<p><a href="https://www.youtube.com/watch?v=kSLJriaOumA">This video</a> from StyleGAN&apos;s creator might help you understand how it works.</p>
<p>If you want to know more about GANs, there&apos;s a repository contains all(I really hope it is) paper that related to GAN<br>
<a href="https://github.com/hindupuravinash/the-gan-zoo">https://github.com/hindupuravinash/the-gan-zoo</a></p>
<p>I think that&apos;s enough of some motivational intro. Now, let&apos;s build our GAN. In this case, DC-GAN.</p>
<h1 class="mume-header" id="implementation">Implementation</h1>

<p>For the sake of easness, we will be using MNIST dataset that already brought by Keras. Let&apos;s first import our library</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token punctuation">,</span> load_model
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Conv2D<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> BatchNormalization<span class="token punctuation">,</span> Dropout
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Reshape<span class="token punctuation">,</span> UpSampling2D<span class="token punctuation">,</span> MaxPooling2D<span class="token punctuation">,</span> Activation
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> mnist<span class="token punctuation">,</span> fashion_mnist
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> SGD<span class="token punctuation">,</span> RMSprop
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>utils <span class="token keyword">import</span> to_categorical

<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
</pre><p>After all the libary are imported, let&apos;s load our data.</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()</span>

X_train <span class="token operator">=</span> <span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">127.5</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">127.5</span> <span class="token comment"># normalization</span>
X_train <span class="token operator">=</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span>
X_test <span class="token operator">=</span> X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span>
</pre><p>The Mnist images are 28x28x1 grayscale of handwritten digits. It contains 60000 set of train data and 10000 set of test data. If you haven&apos;t seen it before, here&apos;s what they looks like</p>
<p><img src="res\mnist-reseachgate.png" alt></p>
<h2 class="mume-header" id="gan-basic-concept">Gan Basic Concept</h2>

<p>GAN is consisted of Generator and Discriminator. In DC-GAN, the Generator and Discriminator are convolutional neural network. Let&apos;s build a simple Generator and Discriminator, then combine them and finally train them.</p>
<h2 class="mume-header" id="helper-functions">Helper Functions</h2>

<p>Some of you might not familiar in practicing with keras, especially building a non-API-ed models such as GAN. Building GAN (and other Deep Learning architecture as well) is like building a lego block. You build them piece-by-piece.</p>
<blockquote>
<p>There should be one&#x2014;and preferably only one&#x2014;obvious way to do it</p>
</blockquote>
<p>So, in order to help you build the GAN, We prepared several helpful function. You are not obligated to understand the codes, but We hope that you can figured out the big picture.</p>
<h4 class="mume-header" id="combine-images">Combine Images</h4>

<p>This function will arrange several images into one frame so that it will be easier to see. This is the sample result:</p>
<p><img src="res\mnist-reseachgate.png" alt></p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">combine_images</span><span class="token punctuation">(</span>generated_images<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num <span class="token operator">=</span> generated_images<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    width <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">)</span>
    height <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token operator">/</span>width<span class="token punctuation">)</span><span class="token punctuation">)</span>
    shape <span class="token operator">=</span> generated_images<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
    image <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>height<span class="token operator">*</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> width<span class="token operator">*</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                     dtype<span class="token operator">=</span>generated_images<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
    <span class="token keyword">for</span> index<span class="token punctuation">,</span> img <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>generated_images<span class="token punctuation">)</span><span class="token punctuation">:</span>
        i <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>index<span class="token operator">/</span>width<span class="token punctuation">)</span>
        j <span class="token operator">=</span> index <span class="token operator">%</span> width
        image<span class="token punctuation">[</span>i<span class="token operator">*</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> j<span class="token operator">*</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token punctuation">(</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> \
            img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> image
</pre><h4 class="mume-header" id="generate-generator">Generate Generator</h4>

<p>Generator are made of several layers. The key idea is to :</p>
<ol>
<li>Get input vector (often called &quot;z&quot;)</li>
<li>Feature Mapping using Dense</li>
<li>Reshape the vector into 2D</li>
<li>Do convolutions</li>
<li>Do uppersamplings</li>
<li>Output the Images</li>
</ol>
<p>Process number 3-4 are often called &quot;transpose convolutions&quot; or &quot;deconvolutions&quot;.<br>
Please note that you can build your own Generator architecture.</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">generator_model</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
        Dense<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> input_dim<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&apos;tanh&apos;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">*</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># This shape related to the reshape and output size</span>
        BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Activation<span class="token punctuation">(</span><span class="token string">&apos;tanh&apos;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        UpSampling2D<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&apos;same&apos;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&apos;tanh&apos;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        UpSampling2D<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Conv2D<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&apos;same&apos;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&apos;tanh&apos;</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model

generator_model<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</pre><h3 class="mume-header" id="discriminator">Discriminator</h3>

<p>The Discriminator in GAN is basically a normal CNN that has to be trained to classify fake or real images. It supposed to work as :</p>
<ol>
<li>Get input image (the fake one, built by Generator)</li>
<li>Do Convolutions</li>
<li>Do subsamplings (or poolings)</li>
<li>Reshape to 1D</li>
<li>Classify using Dense</li>
<li>Output the classification</li>
</ol>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">discriminator_model</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
        Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&apos;same&apos;</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&apos;tanh&apos;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Conv2D<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">&apos;tanh&apos;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Dense<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&apos;tanh&apos;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&apos;sigmoid&apos;</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model

discriminator_model<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</pre><h3 class="mume-header" id="combining-generator-discriminator">Combining Generator + Discriminator</h3>

<p>Now that we previously can create Generator and Discriminator, this function is merely combine both of them into one sequential. Generator first, followed by discriminator.</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">combine_model</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>g<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>d<span class="token punctuation">)</span>
    <span class="token keyword">return</span> model
</pre><p>But it&apos;s not over yet. The model is not ready for training. It must be compiled first. And to compile, we need several hyperparameters in order for them to train well :</p>
<ul>
<li>optimizer (with learning rate)</li>
<li>loss function</li>
</ul>
<p>So, let&apos;s add the hyperparameters in training functions below.</p>
<h3 class="mume-header" id="training-function">Training Function</h3>

<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">train_gan</span><span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> epochs<span class="token punctuation">,</span> g<span class="token punctuation">,</span> d<span class="token punctuation">,</span> save_every<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span> print_every<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token comment"># Get the size of input (Z vector)</span>
    z_size <span class="token operator">=</span> g<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    
    <span class="token comment"># Combine discriminator on generator</span>
    d<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">False</span> <span class="token comment"># set Discriminator to be untrainable before merging</span>
    d_on_g <span class="token operator">=</span> combine_model<span class="token punctuation">(</span>g<span class="token punctuation">,</span> d<span class="token punctuation">)</span>    
    dg_optim <span class="token operator">=</span> RMSprop <span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.0005</span><span class="token punctuation">)</span>
    g_optim <span class="token operator">=</span> RMSprop <span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.0005</span><span class="token punctuation">)</span>
    d_on_g<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">&apos;binary_crossentropy&apos;</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>dg_optim<span class="token punctuation">)</span>
    
    g<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">&apos;binary_crossentropy&apos;</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>g_optim<span class="token punctuation">)</span>
    
    <span class="token comment"># Set Discriminator to be trainable </span>
    d<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">True</span>
    d_optim <span class="token operator">=</span> RMSprop <span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.0005</span><span class="token punctuation">)</span>
    d<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">&apos;binary_crossentropy&apos;</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>d_optim<span class="token punctuation">)</span>
    
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Number of batches&quot;</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">/</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment"># Start training</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\n-------------------------------\nEpoch :&quot;</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>        
        
        <span class="token keyword">for</span> index <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">/</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            
            <span class="token comment"># Randomly generate Z input</span>
            noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> z_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token comment"># Generate fake image from Z </span>
            generated_images <span class="token operator">=</span> g<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>noise<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
            
            <span class="token comment"># Take train data (real image)</span>
            image_batch <span class="token operator">=</span> X_train<span class="token punctuation">[</span>index<span class="token operator">*</span>batch_size<span class="token punctuation">:</span><span class="token punctuation">(</span>index<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>batch_size<span class="token punctuation">]</span>
            
            <span class="token keyword">if</span> index <span class="token operator">%</span> save_every <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                image <span class="token operator">=</span> combine_images<span class="token punctuation">(</span>generated_images<span class="token punctuation">)</span>
                image <span class="token operator">=</span> image<span class="token operator">*</span><span class="token number">127.5</span><span class="token operator">+</span><span class="token number">127.5</span>
                <span class="token comment"># Image.fromarray(image.astype(np.uint8)).save(&quot;train_ep&quot;+</span>
                <span class="token comment">#     str(epoch)+&quot;_&quot;+str(index)+&quot;.png&quot;)</span>
                
                plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>get_cmap<span class="token punctuation">(</span><span class="token string">&apos;gray&apos;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">&apos;off&apos;</span><span class="token punctuation">)</span>
                plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
                
            <span class="token comment"># Concatenate images to train Discriminator</span>
            X <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>image_batch<span class="token punctuation">,</span> generated_images<span class="token punctuation">)</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> batch_size <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> batch_size
            
            <span class="token comment"># Train Discriminator</span>
            d_loss <span class="token operator">=</span> d<span class="token punctuation">.</span>train_on_batch<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>           
            
            <span class="token comment"># Randomly generate z to train Generator</span>
            noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> z_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token comment"># Set Discriminator to be untrainable before training the GAN (for generator)</span>
            d<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">False</span>            
            
            <span class="token comment"># Train GAN (for the generator)</span>
            g_loss <span class="token operator">=</span> d_on_g<span class="token punctuation">.</span>train_on_batch<span class="token punctuation">(</span>noise<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> batch_size<span class="token punctuation">)</span>
            
            <span class="token comment"># Print loss</span>
            <span class="token keyword">if</span> index <span class="token operator">%</span> print_every <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span> 
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;batch %d, g_loss : %f, d_loss : %f&quot;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>index<span class="token punctuation">,</span> g_loss<span class="token punctuation">,</span> d_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
            <span class="token comment"># Set Discriminator to be trainable</span>
            d<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">True</span>       
            
        
    <span class="token keyword">return</span> g<span class="token punctuation">,</span> d
</pre><p>If you think that it&apos;s hard to understand those code, don&apos;t worry. Now let&apos;s move to the main part.</p>
<h2 class="mume-header" id="lets-build-our-gan">Let&apos;s build our GAN</h2>

<h3 class="mume-header" id="initialize-model">Initialize Model</h3>

<pre data-role="codeBlock" data-info="python" class="language-python">z_size <span class="token operator">=</span> <span class="token number">100</span>
g_model <span class="token operator">=</span> generator_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
d_model <span class="token operator">=</span> discriminator_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
</pre><h3 class="mume-header" id="train-gan">Train GAN</h3>

<pre data-role="codeBlock" data-info="python" class="language-python">batch <span class="token operator">=</span> <span class="token number">225</span>
epochs <span class="token operator">=</span> <span class="token number">15</span>
g_model<span class="token punctuation">,</span> d_model <span class="token operator">=</span> train_gan<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span> batch<span class="token punctuation">,</span> epochs<span class="token punctuation">,</span> g_model<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>
</pre><p>Here&apos;s how our model fake images after trained for each epoch</p>
<p><img src="res\GAN-train.PNG" alt><br>
<img src="res\GAN-train-2.PNG" alt></p>
<h3 class="mume-header" id="generate-images">Generate Images</h3>

<p>Now that our model have the understanding of how to draw an mnist image, let&apos;s try to generate one.</p>
<h4 class="mume-header" id="generate-image-only-from-generator">Generate image only from generator</h4>

<p>As we trained our GAN, we trained our Generator to generate fake images (in this case, handwritten digits). So, given an input of random z vector, our Generator is supposed to generate a handwritted images. Let&apos;s try make 100 of it!</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">generate_images</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    z_size <span class="token operator">=</span> g<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> z_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    generated_images <span class="token operator">=</span> g<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>noise<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    image <span class="token operator">=</span> combine_images<span class="token punctuation">(</span>generated_images<span class="token punctuation">)</span>
    filename <span class="token operator">=</span> <span class="token string">&quot;generated_image.png&quot;</span>
    image <span class="token operator">=</span> image<span class="token operator">*</span><span class="token number">127.5</span><span class="token operator">+</span><span class="token number">127.5</span>
    Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>image<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span>filename<span class="token punctuation">)</span>
    <span class="token keyword">return</span> image

images <span class="token operator">=</span> generate_images<span class="token punctuation">(</span>g_model<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>images<span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>get_cmap<span class="token punctuation">(</span><span class="token string">&apos;gray&apos;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">&apos;off&apos;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</pre><p><img src="res\generator-test.PNG" alt></p>
<h4 class="mume-header" id="generate-images-from-generator-with-discriminator-check">Generate images from generator with discriminator check</h4>

<p>Basically our Generator is capable enough to do the job. But is there any possible way to make the generated images looks more realistic?. You&apos;re right ! Pass them to the Discriminator. Previously, our Discriminator has the capability to classify fake images. So, let&apos;s use it as QA agent. If our fake image is classified as real, then, by concept, it should be more realistic than images that clasified as fake. Without furder ado, let&apos;s try it !</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">def</span> <span class="token function">generate_best_images</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> d<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    z_size <span class="token operator">=</span> g<span class="token punctuation">.</span>layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>batch_size<span class="token operator">*</span><span class="token number">20</span><span class="token punctuation">,</span> z_size<span class="token punctuation">)</span><span class="token punctuation">)</span>

    generated_images <span class="token operator">=</span> g<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>noise<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    d_pret <span class="token operator">=</span> d<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>generated_images<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    index <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> batch_size<span class="token operator">*</span><span class="token number">20</span><span class="token punctuation">)</span>
    index<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token operator">*</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    pre_with_index <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>append<span class="token punctuation">(</span>d_pret<span class="token punctuation">,</span> index<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    pre_with_index<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    nice_images <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token punctuation">)</span> <span class="token operator">+</span> generated_images<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    nice_images <span class="token operator">=</span> nice_images<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        idx <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>pre_with_index<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        nice_images<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> generated_images<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>

    image <span class="token operator">=</span> combine_images<span class="token punctuation">(</span>nice_images<span class="token punctuation">)</span>
    filename <span class="token operator">=</span> <span class="token string">&quot;generated_image_best.png&quot;</span>
    image <span class="token operator">=</span> image<span class="token operator">*</span><span class="token number">127.5</span><span class="token operator">+</span><span class="token number">127.5</span>
    Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>image<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span>filename<span class="token punctuation">)</span>
    <span class="token keyword">return</span> image

images <span class="token operator">=</span> generate_best_images<span class="token punctuation">(</span>g_model<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>images<span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>get_cmap<span class="token punctuation">(</span><span class="token string">&apos;gray&apos;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">&apos;off&apos;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</pre><p><img src="res\discriminator-test.PNG" alt></p>
<p>Congratulations! you now can generate realistic handwritten images using Generator and Discriminator simultaneuosly. What? you want to generate specific number?</p>
<h2 class="mume-header" id="latent-vector-operations">Latent Vector Operations</h2>

<p>It was found that the z vector of specific class tends to have a similarity. It&apos;s later said that for a specific class, there should be a vector z that represent it. Now it&apos;s called Latent Vector. So, in order to create image of number &quot;1&quot;, you can easily do an average of z vector that generates &quot;1&quot;, use it as input of Generator, and Voila ! You will create a number &quot;1&quot; (conceptually).</p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p><a href="https://arxiv.org/pdf/1406.2661.pdf">Goodfellow, Ian J. - Generative Adversarial Nets, 2014</a> <a href="#fnref1" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn2" class="footnote-item"><p><a href="https://arxiv.org/abs/1411.1784">Mirza, M. -  Conditional Generative Adversarial Nets, 2014</a> <a href="#fnref2" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn3" class="footnote-item"><p><a href="https://arxiv.org/abs/1703.10593v6">Zhu, JY. et al - Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, 2018</a> <a href="#fnref3" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn4" class="footnote-item"><p><a href="https://arxiv.org/abs/1805.08318v1">Zhang, Han - Self-Attention Generative Adversarial Network. 2018</a> <a href="#fnref4" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn5" class="footnote-item"><p><a href="https://arxiv.org/abs/1710.10196">Karras, Tero- Progressive Growing of GANs for Improved Quality Stability and Variation, 2018</a> <a href="#fnref5" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn6" class="footnote-item"><p><a href="https://arxiv.org/abs/1809.11096v2">Brock, Andrew - Large Scale GAN Training for High Fidelity Natural Image Synthesis, 2019</a> <a href="#fnref6" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
<li id="fn7" class="footnote-item"><p><a href="https://arxiv.org/abs/1812.04948">Karras, Tero - A Style-Based Generator Architecture for Generative Adversarial Networks, 2019</a> <a href="#fnref7" class="footnote-backref">&#x21A9;&#xFE0E;</a></p>
</li>
</ol>
</section>

      </div>
      
      
    
    
    
    
    
    
    
    
  
    </body></html>